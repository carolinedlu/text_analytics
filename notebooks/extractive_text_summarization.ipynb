{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe92f8c",
   "metadata": {},
   "source": [
    "# ISSS609 Text Analytics and Applications\n",
    "## IMBD Movie Review - Extractive Text Summarisation\n",
    "### G1 - Group 4\n",
    "\n",
    "<a id=\"table_of_contents\"></a>\n",
    "### Table of Contents\n",
    "\n",
    "1. [Importing Files and Libraries](#import)\n",
    "2. [Extractive Summarisation steps](#outline)\n",
    "3. [Importing raw data](#setup)\n",
    "4. [Creating a frequency table](#freq)\n",
    "5. [Calculate sentence scores](#ss)\n",
    "6. [Calculate threshold](#threshold)\n",
    "7. [Finetuning threshold](#finetune)\n",
    "8. [Programmatic evaluation](#eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452dba5",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "### 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e9d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from text_analytics.config import DATA_PATH\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import List, Any\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "# set custom colwidths \n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2f9b4",
   "metadata": {},
   "source": [
    "<a id=\"outline\"></a>\n",
    "### 2. Extractive summarisation steps\n",
    "\n",
    "Here is an outline of steps to build the extractive summariser \n",
    "\n",
    "- Select a raw article to preprocess \n",
    "- Tokenise the sentences to get all stems present \n",
    "- Evaluate the weighted occurrence frequency of the words \n",
    "- Split the paragraph into sentences\n",
    "- Apply the masking threshold to output the summarised review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefaa7c",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "### 3. Importing raw data\n",
    "\n",
    "- A raw article is selected at this stage for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e7765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometim...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;Thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometim...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />Thi...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_parquet(DATA_PATH / \"imdb_data.parquet\")\n",
    "# preview the dataframe\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8321737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.review = movie_reviews.review.replace(r\"<.*?>\",\" \", regex=True)\n",
    "movie_reviews.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e87ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n"
     ]
    }
   ],
   "source": [
    "article = movie_reviews.loc[5, \"review\"]\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191493",
   "metadata": {},
   "source": [
    "<a id=\"freq\"></a>\n",
    "### 4. Creating a frequency table\n",
    "\n",
    "- The first step in extractive summarisation is to determine the relative importance of each word within the overall contabs of the sentence \n",
    "- Every stem in an article's importance can be captured into a frequency table and weighted accordingly\n",
    "- We remove stop words and calculate a frequency table for each article  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6ef10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary_table(article, stemmer = None):\n",
    "    #removing stop words\n",
    "    frequency_table = defaultdict(int)\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    punct = set(string.punctuation)\n",
    "    \n",
    "    check_set = stop_words.union(punct)\n",
    "    word_vector = word_tokenize(article)\n",
    "\n",
    "    # instantiate the stemmer \n",
    "    if stemmer is None: \n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "    stemmed_word_vector = [stemmer.stem(word) for word in word_vector]\n",
    "    for word in stemmed_word_vector:\n",
    "        if word not in check_set and word.isalnum():\n",
    "            frequency_table[word] += 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564ae38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table = create_dictionary_table(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74e265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobl</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onli</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      frequencies\n",
       "movi            2\n",
       "nobl            1\n",
       "old             1\n",
       "one             1\n",
       "onli            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.DataFrame(\n",
    "    {\"frequencies\": frequency_table}\n",
    "    ).sort_values(\"frequencies\", ascending=False)\n",
    "# preview the frequencies\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47745c",
   "metadata": {},
   "source": [
    "<a id=\"ss\"></a>\n",
    "### 5. Calculate sentence scores\n",
    "\n",
    "- The frequency scores are used to determine the importance of each sentence \n",
    "- For instance, `I like this movie` will return a score of 3 if `like=1` and `movie=2`\n",
    "- To ensure long sentences do not dominate shorter sentences, we normalise the scores of each sentence by dividing each sentence score by its word length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc75488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_scores(sentences: npt.ArrayLike, frequency_table: dict) -> dict:   \n",
    "    # Every sentence is scored by how important its constituent words are in the frequency table\n",
    "    sentence_weights = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "\n",
    "        for word_weight in frequency_table:\n",
    "            sentence_weights[sentence[:7]] += frequency_table[word_weight]\n",
    "\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "\n",
    "        sentence_weights[sentence[:7]] /= sentence_wordcount_without_stop_words\n",
    "\n",
    "    return sentence_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de87c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ae13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_weights = calculate_sentence_scores(sentences, frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b81660dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>If I ha</th>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And the</th>\n",
       "      <td>7.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It just</th>\n",
       "      <td>6.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probabl</th>\n",
       "      <td>6.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The kid</th>\n",
       "      <td>6.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_weights\n",
       "If I ha         13.400000\n",
       "And the          7.444444\n",
       "It just          6.700000\n",
       "Probabl          6.090909\n",
       "The kid          6.090909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_weight_preview = pd.DataFrame(\n",
    "    {\"sentence_weights\": sentence_weights}\n",
    "    ).sort_values(\"sentence_weights\", ascending=False)\n",
    "sentence_weight_preview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af700a85",
   "metadata": {},
   "source": [
    "<a id=\"threshold\"></a>\n",
    "### 6. Calculate the threshold for a token to be counted as important \n",
    "\n",
    "- We can adjust the threshold by multiplying the mean of the scores by an alpha value\n",
    "- Alternatives, such as the median, can also be used to compute the threshold for inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d280d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_score(sentence_weights: dict, alpha: float = 1.0) -> float:\n",
    "    return np.mean(list(sentence_weights.values())) * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07abb8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold weight for example article: 7.55\n"
     ]
    }
   ],
   "source": [
    "print(f\"Threshold weight for example article: {calculate_threshold_score(sentence_weights):.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52555d3",
   "metadata": {},
   "source": [
    "<a id=\"finetune\"></a>\n",
    "### 7. Finetuning the threshold \n",
    "\n",
    "- Different threshold values represent a trade-off between comprehension and length\n",
    "- Lower thresholds result in longer sentences, but will contain more contabsual markers\n",
    "- The optimal threshold can either be determined manually or programmatically via a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06727bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_summary(sentences: npt.ArrayLike, sentence_weights: dict, threshold: float) -> str:\n",
    "    article_summary = [sentence for sentence in sentences if sentence[:7] in sentence_weights and sentence_weights.get(sentence[:7]) >= threshold]\n",
    "    return \" \".join(article_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4cd855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.8, 0.9, 1. , 1.1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = np.arange(0.7, 1.1, 0.1)\n",
    "alpha_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9bc1c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold of: 0.70\n",
      "Result: Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 0.80\n",
      "Result: Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 0.90\n",
      "Result: And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 1.00\n",
      "Result: If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 1.10\n",
      "Result: If I had a dozen thumbs, they'd all be \"up\" for this movie.\n"
     ]
    }
   ],
   "source": [
    "for alpha in alpha_values: \n",
    "    threshold_score = calculate_threshold_score(sentence_weights=sentence_weights, alpha=alpha) \n",
    "    final_result = get_article_summary(sentences=sentences, sentence_weights=sentence_weights, threshold=threshold_score) \n",
    "\n",
    "    print(f\"At threshold of: {alpha:.02f}\")\n",
    "    print(f\"Result: {final_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af05ae",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "\n",
    "### 8. Programmatic evaluation\n",
    "\n",
    "- We wrap up all the previous steps into an `ExtractiveTabsSummarizer` class \n",
    "- To evaluate the effectiveness of the summarisation, we have manually summarised 101 movie reviews \n",
    "- Our human-labelled summary serves as a reference to estimate the algorithm's ability to pick out important aspects of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5e1513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty it was surreal, I couldn't say I was ready for it. As I watched more I developed a taste for Oz, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...</td>\n",
       "      <td>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...</td>\n",
       "      <td>Woody Allen is still fully in control of the style many of us have grown to love. The plot is simplistic, but the dialogue is witty and the charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.This movie is s...</td>\n",
       "      <td>This movie is slower than a soap opera. As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...</td>\n",
       "      <td>This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. Director Petter M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "1  A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is s...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...   \n",
       "\n",
       "                                                                                                                                                 Summary  \n",
       "0  The first episode I saw struck me as so nasty it was surreal, I couldn't say I was ready for it. As I watched more I developed a taste for Oz, and...  \n",
       "1  A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...  \n",
       "2  Woody Allen is still fully in control of the style many of us have grown to love. The plot is simplistic, but the dialogue is witty and the charac...  \n",
       "3  This movie is slower than a soap opera. As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jak...  \n",
       "4  This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. Director Petter M...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine tune based on average Rouge-1 F1 score\n",
    "labelled_movie_reviews = pd.read_csv(\"../data/review_evaluation.csv\", index_col=0).iloc[:,:2]  #csv contains review and human summary\n",
    "labelled_movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "867aadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import List, Any\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "class ExtractiveTextSummarizer:\n",
    "    def __init__(self, article: str, alpha: float = 1.0) -> None:\n",
    "        self.article = article\n",
    "        self.alpha = alpha         \n",
    "        self.frequency_table = defaultdict(int)\n",
    "\n",
    "    def _create_dictionary_table(self, stemmer: Any = None) -> dict:\n",
    "   \n",
    "        #removing stop words\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        punct = set(string.punctuation)\n",
    "        check_set = stop_words.union(punct) # remove punctuation\n",
    "        word_vector = word_tokenize(self.article)\n",
    "\n",
    "        # instantiate the stemmer \n",
    "        if stemmer is None: \n",
    "            stemmer = PorterStemmer()\n",
    "\n",
    "        stemmed_word_vector = [stemmer.stem(word) for word in word_vector]\n",
    "        for word in stemmed_word_vector:\n",
    "            if word not in check_set and word.isalnum():\n",
    "                self.frequency_table[word] += 1\n",
    "\n",
    "        return self.frequency_table\n",
    "\n",
    "\n",
    "    def _calculate_sentence_scores(self, sentences: npt.ArrayLike) -> dict:   \n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_weights = defaultdict(int)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_wordcount_without_stop_words = 0\n",
    "\n",
    "            for word_weight in self.frequency_table:\n",
    "                sentence_weights[sentence[:7]] += self.frequency_table[word_weight]\n",
    "\n",
    "                if word_weight in sentence.lower():\n",
    "                    sentence_wordcount_without_stop_words += 1\n",
    "\n",
    "            if sentence_wordcount_without_stop_words: \n",
    "                sentence_weights[sentence[:7]] /= sentence_wordcount_without_stop_words\n",
    "            else:\n",
    "                sentence_weights[sentence[:7]] = 0\n",
    "\n",
    "        return sentence_weights\n",
    "\n",
    "\n",
    "    def _calculate_threshold_score(self, sentence_weight: dict) -> float:\n",
    "        return np.mean(list(sentence_weight.values())) * self.alpha\n",
    "\n",
    "\n",
    "    def _get_article_summary(self, sentences: npt.ArrayLike, sentence_weights: dict, threshold: float) -> str:\n",
    "        article_summary = [sentence for sentence in sentences if sentence[:7] in sentence_weights and sentence_weights.get(sentence[:7]) >= threshold]\n",
    "\n",
    "        return \" \".join(article_summary)\n",
    "\n",
    "    def run_article_summary(self):\n",
    "\n",
    "        #creating a dictionary for the word frequency table\n",
    "        _ = self._create_dictionary_table()\n",
    "\n",
    "        #tokenizing the sentences\n",
    "        sentences = sent_tokenize(self.article)\n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_scores = self._calculate_sentence_scores(sentences)\n",
    "\n",
    "        # getting the threshold\n",
    "        threshold = self._calculate_threshold_score(sentence_scores)\n",
    "\n",
    "        #producing the summary\n",
    "        article_summary = self._get_article_summary(sentences, sentence_scores, threshold)\n",
    "\n",
    "        return article_summary\n",
    "\n",
    "    def get_rouge_score(self, hypothesis_text: str, reference_text: str) -> npt.ArrayLike:\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hypothesis_text, reference_text)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38a466",
   "metadata": {},
   "source": [
    "the error here is to show when alpha = 1.5, the threshold is too high to generate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1f671a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Hypothesis is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siyuf\\Documents\\GitHub\\text_analytics\\notebooks\\extractive_text_summarization.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m labelled_movie_reviews[\u001b[39m'\u001b[39m\u001b[39mext_review\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ext_review\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m ref, ext_review \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(labelled_movie_reviews[\u001b[39m'\u001b[39m\u001b[39mSummary\u001b[39m\u001b[39m'\u001b[39m], labelled_movie_reviews[\u001b[39m'\u001b[39m\u001b[39mext_review\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     score \u001b[39m=\u001b[39m extractive_summarizer\u001b[39m.\u001b[39;49mget_rouge_score(hypothesis_text\u001b[39m=\u001b[39;49mext_review, reference_text\u001b[39m=\u001b[39;49mref)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ext_recall\u001b[39m.\u001b[39mappend(score[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrouge-1\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ext_precision\u001b[39m.\u001b[39mappend(score[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrouge-1\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\siyuf\\Documents\\GitHub\\text_analytics\\notebooks\\extractive_text_summarization.ipynb Cell 30\u001b[0m in \u001b[0;36mExtractiveTextSummarizer.get_rouge_score\u001b[1;34m(self, hypothesis_text, reference_text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_rouge_score\u001b[39m(\u001b[39mself\u001b[39m, hypothesis_text: \u001b[39mstr\u001b[39m, reference_text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m npt\u001b[39m.\u001b[39mArrayLike:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     rouge \u001b[39m=\u001b[39m Rouge()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     scores \u001b[39m=\u001b[39m rouge\u001b[39m.\u001b[39;49mget_scores(hypothesis_text, reference_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyuf/Documents/GitHub/text_analytics/notebooks/extractive_text_summarization.ipynb#Y111sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\siyuf\\anaconda3\\lib\\site-packages\\rouge\\rouge.py:107\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(hyps) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avg:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scores(hyps, refs)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_avg_scores(hyps, refs)\n",
      "File \u001b[1;32mc:\\Users\\siyuf\\anaconda3\\lib\\site-packages\\rouge\\rouge.py:120\u001b[0m, in \u001b[0;36mRouge._get_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[0;32m    119\u001b[0m     fn \u001b[39m=\u001b[39m Rouge\u001b[39m.\u001b[39mAVAILABLE_METRICS[m]\n\u001b[1;32m--> 120\u001b[0m     sc \u001b[39m=\u001b[39m fn(\n\u001b[0;32m    121\u001b[0m         hyp,\n\u001b[0;32m    122\u001b[0m         ref,\n\u001b[0;32m    123\u001b[0m         raw_results\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_results,\n\u001b[0;32m    124\u001b[0m         exclusive\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclusive)\n\u001b[0;32m    125\u001b[0m     sen_score[m] \u001b[39m=\u001b[39m {s: sc[s] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstats}\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_lengths:\n",
      "File \u001b[1;32mc:\\Users\\siyuf\\anaconda3\\lib\\site-packages\\rouge\\rouge.py:53\u001b[0m, in \u001b[0;36mRouge.<lambda>\u001b[1;34m(hyp, ref, **k)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mRouge\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     DEFAULT_METRICS \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mrouge-1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrouge-2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrouge-l\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     52\u001b[0m     AVAILABLE_METRICS \u001b[39m=\u001b[39m {\n\u001b[1;32m---> 53\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-1\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk: rouge_score\u001b[39m.\u001b[39;49mrouge_n(hyp, ref, \u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk),\n\u001b[0;32m     54\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-2\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk: rouge_score\u001b[39m.\u001b[39mrouge_n(hyp, ref, \u001b[39m2\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk),\n\u001b[0;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-3\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk: rouge_score\u001b[39m.\u001b[39mrouge_n(hyp, ref, \u001b[39m3\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk),\n\u001b[0;32m     56\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-4\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk: rouge_score\u001b[39m.\u001b[39mrouge_n(hyp, ref, \u001b[39m4\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk),\n\u001b[0;32m     57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-5\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk: rouge_score\u001b[39m.\u001b[39mrouge_n(hyp, ref, \u001b[39m5\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk),\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrouge-l\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk:\n\u001b[0;32m     59\u001b[0m             rouge_score\u001b[39m.\u001b[39mrouge_l_summary_level(hyp, ref, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk),\n\u001b[0;32m     60\u001b[0m     }\n\u001b[0;32m     61\u001b[0m     DEFAULT_STATS \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     62\u001b[0m     AVAILABLE_STATS \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\siyuf\\anaconda3\\lib\\site-packages\\rouge\\rouge_score.py:253\u001b[0m, in \u001b[0;36mrouge_n\u001b[1;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mComputes ROUGE-N of two text collections of sentences.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mSourece: http://research.microsoft.com/en-us/um/people/cyl/download/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39m  ValueError: raises exception if a param has len <= 0\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(evaluated_sentences) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mHypothesis is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(reference_sentences) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    255\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mReference is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Hypothesis is empty."
     ]
    }
   ],
   "source": [
    "ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "for review in labelled_movie_reviews['review']:\n",
    "    extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=1.5)\n",
    "    ext_review.append(extractive_summarizer.run_article_summary())\n",
    "labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "for ref, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "    score = extractive_summarizer.get_rouge_score(hypothesis_text=ext_review, reference_text=ref)\n",
    "    ext_recall.append(score[0]['rouge-1']['r'])\n",
    "    ext_precision.append(score[0]['rouge-1']['p'])\n",
    "    ext_f1.append(score[0]['rouge-1']['f'])\n",
    "    \n",
    "labelled_movie_reviews['ext_recall'] = ext_recall\n",
    "labelled_movie_reviews['ext_precision'] = ext_precision\n",
    "labelled_movie_reviews['ext_f1'] = ext_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76808efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.95</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rouge-1 Recall score</th>\n",
       "      <td>0.500529</td>\n",
       "      <td>0.455571</td>\n",
       "      <td>0.404160</td>\n",
       "      <td>0.371538</td>\n",
       "      <td>0.338690</td>\n",
       "      <td>0.319733</td>\n",
       "      <td>0.295041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge-1 Precision score</th>\n",
       "      <td>0.348047</td>\n",
       "      <td>0.353841</td>\n",
       "      <td>0.348464</td>\n",
       "      <td>0.342638</td>\n",
       "      <td>0.342938</td>\n",
       "      <td>0.344217</td>\n",
       "      <td>0.349930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge-1 F1 score</th>\n",
       "      <td>0.369096</td>\n",
       "      <td>0.355662</td>\n",
       "      <td>0.331793</td>\n",
       "      <td>0.314705</td>\n",
       "      <td>0.298958</td>\n",
       "      <td>0.290326</td>\n",
       "      <td>0.276529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg length</th>\n",
       "      <td>480.900990</td>\n",
       "      <td>432.257426</td>\n",
       "      <td>389.415842</td>\n",
       "      <td>355.801980</td>\n",
       "      <td>310.821782</td>\n",
       "      <td>282.386139</td>\n",
       "      <td>258.495050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0.70        0.75        0.80        0.85  \\\n",
       "Rouge-1 Recall score       0.500529    0.455571    0.404160    0.371538   \n",
       "Rouge-1 Precision score    0.348047    0.353841    0.348464    0.342638   \n",
       "Rouge-1 F1 score           0.369096    0.355662    0.331793    0.314705   \n",
       "avg length               480.900990  432.257426  389.415842  355.801980   \n",
       "\n",
       "                               0.90        0.95        1.00  \n",
       "Rouge-1 Recall score       0.338690    0.319733    0.295041  \n",
       "Rouge-1 Precision score    0.342938    0.344217    0.349930  \n",
       "Rouge-1 F1 score           0.298958    0.290326    0.276529  \n",
       "avg length               310.821782  282.386139  258.495050  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_tune_results = pd.DataFrame(index=['Rouge-1 Recall score', 'Rouge-1 Precision score', 'Rouge-1 F1 score', 'avg length'])\n",
    "# lower alpha will result in longer summary, we try to keep it short\n",
    "for al in [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]:\n",
    "    ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "    for review in labelled_movie_reviews['review']:\n",
    "        extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=al)\n",
    "        ext_review.append(extractive_summarizer.run_article_summary())\n",
    "    labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "    for ref, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "        score = extractive_summarizer.get_rouge_score(hypothesis_text=ext_review, reference_text=ref)\n",
    "        ext_recall.append(score[0]['rouge-1']['r'])\n",
    "        ext_precision.append(score[0]['rouge-1']['p'])\n",
    "        ext_f1.append(score[0]['rouge-1']['f'])\n",
    "\n",
    "    alpha_tune_results[al] = [np.mean(ext_recall), np.mean(ext_precision), np.mean(ext_f1), labelled_movie_reviews['ext_review'].apply(len).mean()]\n",
    "\n",
    "alpha_tune_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee93269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "for review in labelled_movie_reviews['review']:\n",
    "    extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=0.7)\n",
    "    ext_review.append(extractive_summarizer.run_article_summary())\n",
    "labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "for ref, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "    score = extractive_summarizer.get_rouge_score(hypothesis_text=ext_review, reference_text=ref)\n",
    "    ext_recall.append(score[0]['rouge-1']['r'])\n",
    "    ext_precision.append(score[0]['rouge-1']['p'])\n",
    "    ext_f1.append(score[0]['rouge-1']['f'])\n",
    "\n",
    "labelled_movie_reviews['ext_recall'] = ext_recall\n",
    "labelled_movie_reviews['ext_precision'] = ext_precision\n",
    "labelled_movie_reviews['ext_f1'] = ext_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf0b2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>ext_review</th>\n",
       "      <th>ext_recall</th>\n",
       "      <th>ext_precision</th>\n",
       "      <th>ext_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty it was surreal, I couldn't say I was ready for it. As I watched more I developed a taste for Oz, and...</td>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.253165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...</td>\n",
       "      <td>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...</td>\n",
       "      <td>A wonderful little production. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices dow...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...</td>\n",
       "      <td>Woody Allen is still fully in control of the style many of us have grown to love. The plot is simplistic, but the dialogue is witty and the charac...</td>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.520325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "1  A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...   \n",
       "\n",
       "                                                                                                                                                 Summary  \\\n",
       "0  The first episode I saw struck me as so nasty it was surreal, I couldn't say I was ready for it. As I watched more I developed a taste for Oz, and...   \n",
       "1  A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomfor...   \n",
       "2  Woody Allen is still fully in control of the style many of us have grown to love. The plot is simplistic, but the dialogue is witty and the charac...   \n",
       "\n",
       "                                                                                                                                              ext_review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "1  A wonderful little production. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices dow...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...   \n",
       "\n",
       "   ext_recall  ext_precision    ext_f1  \n",
       "0    0.444444       0.176991  0.253165  \n",
       "1    0.575000       0.638889  0.605263  \n",
       "2    0.780488       0.390244  0.520325  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_movie_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a35c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>0.500529</td>\n",
       "      <td>0.348047</td>\n",
       "      <td>0.369096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIAN</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.356436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Recall  Precision        F1\n",
       "MEAN    0.500529   0.348047  0.369096\n",
       "MAX     1.000000   1.000000  0.916667\n",
       "MIN     0.000000   0.000000  0.000000\n",
       "MEDIAN  0.509091   0.333333  0.356436"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.DataFrame(index=['MEAN', 'MAX', 'MIN', 'MEDIAN'], columns=['Recall', 'Precision', 'F1'])\n",
    "#f1_list, recall_list, precision_list = [],[],[]\n",
    "f1_list = [np.mean(labelled_movie_reviews['ext_f1']), max(labelled_movie_reviews['ext_f1']), \\\n",
    "               min(labelled_movie_reviews['ext_f1']), np.median(labelled_movie_reviews['ext_f1'])]\n",
    "\n",
    "recall_list = [np.mean(labelled_movie_reviews['ext_recall']), max(labelled_movie_reviews['ext_recall']), \\\n",
    "               min(labelled_movie_reviews['ext_recall']), np.median(labelled_movie_reviews['ext_recall'])]\n",
    "\n",
    "precision_list = [np.mean(labelled_movie_reviews['ext_precision']), max(labelled_movie_reviews['ext_precision']), \\\n",
    "               min(labelled_movie_reviews['ext_precision']), np.median(labelled_movie_reviews['ext_precision'])]\n",
    "\n",
    "stat['Recall'] = recall_list\n",
    "stat['Precision'] = precision_list\n",
    "stat['F1'] = f1_list\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b2fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_movie_reviews.to_csv(\"../data/ext_review_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed142f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c13d69c397d2de6a9cad7616001f1ca9dadfc7579438a900a26d61d34a4c908e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
