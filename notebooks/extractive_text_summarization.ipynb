{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe92f8c",
   "metadata": {},
   "source": [
    "# ISSS609 Text Analytics and Applications\n",
    "## IMBD Movie Review - Extractive Text Summarisation\n",
    "### G1 - Group 4\n",
    "\n",
    "<a id=\"table_of_contents\"></a>\n",
    "### Table of Contents\n",
    "\n",
    "1. [Importing Files and Libraries](#import)\n",
    "2. [Extractive Summarisation steps](#outline)\n",
    "3. [Importing raw data](#setup)\n",
    "4. [Creating a frequency table](#freq)\n",
    "5. [Calculate sentence scores](#ss)\n",
    "6. [Calculate threshold](#threshold)\n",
    "7. [Finetuning threshold](#finetune)\n",
    "8. [Programmatic evaluation](#eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452dba5",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "### 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e9d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from text_analytics.config import DATA_PATH\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import List, Any\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "# set custom colwidths \n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2f9b4",
   "metadata": {},
   "source": [
    "<a id=\"outline\"></a>\n",
    "### 2. Extractive summarisation steps\n",
    "\n",
    "Here is an outline of steps to build the extractive summariser \n",
    "\n",
    "- Select a raw article to preprocess \n",
    "- Tokenise the sentences to get all stems present \n",
    "- Evaluate the weighted occurrence frequency of the words \n",
    "- Split the paragraph into sentences\n",
    "- Apply the masking threshold to output the summarised review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefaa7c",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "### 3. Importing raw data\n",
    "\n",
    "- A raw article is selected at this stage for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e7765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometim...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;Thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened ...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometim...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted ...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />Thi...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. Thi...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_parquet(DATA_PATH / \"imdb_data.parquet\")\n",
    "# preview the dataframe\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e87ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n"
     ]
    }
   ],
   "source": [
    "article = movie_reviews.loc[5, \"review\"]\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191493",
   "metadata": {},
   "source": [
    "<a id=\"freq\"></a>\n",
    "### 4. Creating a frequency table\n",
    "\n",
    "- The first step in extractive summarisation is to determine the relative importance of each word within the overall context of the sentence \n",
    "- Every stem in an article's importance can be captured into a frequency table and weighted accordingly\n",
    "- We remove stop words and calculate a frequency table for each article  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6ef10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary_table(article, stemmer = None):\n",
    "    #removing stop words\n",
    "    frequency_table = defaultdict(int)\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_vector = word_tokenize(article)\n",
    "\n",
    "    # instantiate the stemmer \n",
    "    if stemmer is None: \n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "    stemmed_word_vector = [stemmer.stem(word) for word in word_vector]\n",
    "    for word in stemmed_word_vector:\n",
    "        if word not in stop_words:\n",
    "            frequency_table[word] += 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564ae38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table = create_dictionary_table(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74e265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      frequencies\n",
       ",              11\n",
       ".               6\n",
       "'s              3\n",
       "movi            2\n",
       "''              2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.DataFrame(\n",
    "    {\"frequencies\": frequency_table}\n",
    "    ).sort_values(\"frequencies\", ascending=False)\n",
    "# preview the frequencies\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b536ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kid</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        frequencies\n",
       ",                11\n",
       ".                 6\n",
       "'s                3\n",
       "movi              2\n",
       "''                2\n",
       "...             ...\n",
       "happen            1\n",
       "kid               1\n",
       "last              1\n",
       "like              1\n",
       "year              1\n",
       "\n",
       "[65 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47745c",
   "metadata": {},
   "source": [
    "<a id=\"ss\"></a>\n",
    "### 5. Calculate sentence scores\n",
    "\n",
    "- The frequency scores are used to determine the importance of each sentence \n",
    "- For instance, `I like this movie` will return a score of 3 if `like=1` and `movie=2`\n",
    "- To ensure long sentences do not dominate shorter sentences, we normalise the scores of each sentence by dividing each sentence score by its word length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34078b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc75488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_scores(sentences: npt.ArrayLike, frequency_table: dict) -> dict:   \n",
    "    # Every sentence is scored by how important its constituent words are in the frequency table\n",
    "    sentence_weights = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "\n",
    "        for word_weight in frequency_table:\n",
    "            sentence_weights[sentence[:7]] += frequency_table[word_weight]\n",
    "\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "\n",
    "        sentence_weights[sentence[:7]] /= sentence_wordcount_without_stop_words\n",
    "\n",
    "    return sentence_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ae13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_weights = calculate_sentence_scores(sentences, frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81660dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>If I ha</th>\n",
       "      <td>10.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And the</th>\n",
       "      <td>7.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It just</th>\n",
       "      <td>7.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The kid</th>\n",
       "      <td>6.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probabl</th>\n",
       "      <td>6.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_weights\n",
       "If I ha         10.625000\n",
       "And the          7.727273\n",
       "It just          7.083333\n",
       "The kid          6.538462\n",
       "Probabl          6.071429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_weight_preview = pd.DataFrame(\n",
    "    {\"sentence_weights\": sentence_weights}\n",
    "    ).sort_values(\"sentence_weights\", ascending=False)\n",
    "sentence_weight_preview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af700a85",
   "metadata": {},
   "source": [
    "<a id=\"threshold\"></a>\n",
    "### 6. Calculate the threshold for a token to be counted as important \n",
    "\n",
    "- We can adjust the threshold by multiplying the mean of the scores by an alpha value\n",
    "- Alternatives, such as the median, can also be used to compute the threshold for inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d280d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_score(sentence_weights: dict, alpha: float = 1.0) -> float:\n",
    "    return np.mean(list(sentence_weights.values())) * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07abb8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold weight for example article: 7.29\n"
     ]
    }
   ],
   "source": [
    "print(f\"Threshold weight for example article: {calculate_threshold_score(sentence_weights):.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52555d3",
   "metadata": {},
   "source": [
    "<a id=\"finetune\"></a>\n",
    "### 7. Finetuning the threshold \n",
    "\n",
    "- Different threshold values represent a trade-off between comprehension and length\n",
    "- Lower thresholds result in longer sentences, but will contain more contextual markers\n",
    "- The optimal threshold can either be determined manually or programmatically via a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06727bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_summary(sentences: npt.ArrayLike, sentence_weights: dict, threshold: float) -> str:\n",
    "    article_summary = [sentence for sentence in sentences if sentence[:7] in sentence_weights and sentence_weights.get(sentence[:7]) >= threshold]\n",
    "    return \" \".join(article_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4cd855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95, 1.05, 1.15, 1.25])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = np.arange(0.95, 1.25, 0.1)\n",
    "alpha_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9bc1c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold of: 0.95\n",
      "Result: It just never gets old, despite my having seen it some 15 or more times in the last 25 years. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 1.05\n",
      "Result: And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 1.15\n",
      "Result: If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "At threshold of: 1.25\n",
      "Result: If I had a dozen thumbs, they'd all be \"up\" for this movie.\n"
     ]
    }
   ],
   "source": [
    "for alpha in alpha_values: \n",
    "    threshold_score = calculate_threshold_score(sentence_weights=sentence_weights, alpha=alpha) \n",
    "    final_result = get_article_summary(sentences=sentences, sentence_weights=sentence_weights, threshold=threshold_score) \n",
    "\n",
    "    print(f\"At threshold of: {alpha:.02f}\")\n",
    "    print(f\"Result: {final_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf390e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5e1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune based on average Rouge-1 F1 score\n",
    "labelled_movie_reviews = pd.read_csv(\"../data/review_evaluation.csv\", index_col=0).iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "867aadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import List, Any\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "class ExtractiveTextSummarizer:\n",
    "    def __init__(self, article: str, alpha: float = 1.0) -> None:\n",
    "        self.article = article\n",
    "        self.alpha = alpha         \n",
    "        self.frequency_table = defaultdict(int)\n",
    "\n",
    "    def _create_dictionary_table(self, stemmer: Any = None) -> dict:\n",
    "   \n",
    "        #removing stop words\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        punct = set(string.punctuation)\n",
    "        check_set = stop_words.union(punct) # remove punctuation\n",
    "        word_vector = word_tokenize(self.article)\n",
    "\n",
    "        # instantiate the stemmer \n",
    "        if stemmer is None: \n",
    "            stemmer = PorterStemmer()\n",
    "\n",
    "        stemmed_word_vector = [stemmer.stem(word) for word in word_vector]\n",
    "        for word in stemmed_word_vector:\n",
    "            if word not in check_set:\n",
    "                self.frequency_table[word] += 1\n",
    "\n",
    "        return self.frequency_table\n",
    "\n",
    "\n",
    "    def _calculate_sentence_scores(self, sentences: npt.ArrayLike) -> dict:   \n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_weights = defaultdict(int)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_wordcount_without_stop_words = 0\n",
    "\n",
    "            for word_weight in self.frequency_table:\n",
    "                sentence_weights[sentence[:7]] += self.frequency_table[word_weight]\n",
    "\n",
    "                if word_weight in sentence.lower():\n",
    "                    sentence_wordcount_without_stop_words += 1\n",
    "\n",
    "            if sentence_wordcount_without_stop_words: \n",
    "                sentence_weights[sentence[:7]] /= sentence_wordcount_without_stop_words\n",
    "            else:\n",
    "                sentence_weights[sentence[:7]] = 0\n",
    "\n",
    "        return sentence_weights\n",
    "\n",
    "\n",
    "    def _calculate_threshold_score(self, sentence_weight: dict) -> float:\n",
    "        return np.mean(list(sentence_weight.values())) * self.alpha\n",
    "\n",
    "\n",
    "    def _get_article_summary(self, sentences: npt.ArrayLike, sentence_weights: dict, threshold: float) -> str:\n",
    "        article_summary = [sentence for sentence in sentences if sentence[:7] in sentence_weights and sentence_weights.get(sentence[:7]) >= threshold]\n",
    "\n",
    "        return \" \".join(article_summary)\n",
    "\n",
    "    def run_article_summary(self):\n",
    "\n",
    "        #creating a dictionary for the word frequency table\n",
    "        _ = self._create_dictionary_table()\n",
    "\n",
    "        #tokenizing the sentences\n",
    "        sentences = sent_tokenize(self.article)\n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_scores = self._calculate_sentence_scores(sentences)\n",
    "\n",
    "        # getting the threshold\n",
    "        threshold = self._calculate_threshold_score(sentence_scores)\n",
    "\n",
    "        #producing the summary\n",
    "        article_summary = self._get_article_summary(sentences, sentence_scores, threshold)\n",
    "\n",
    "        return article_summary\n",
    "\n",
    "    def get_rouge_score(self, hypothesis_text: str, reference_text: str) -> npt.ArrayLike:\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hypothesis_text, reference_text)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d1f671a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m labelled_movie_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     extractive_summarizer \u001b[38;5;241m=\u001b[39m ExtractiveTextSummarizer(article\u001b[38;5;241m=\u001b[39mreview, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     ext_review\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextractive_summarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_article_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m labelled_movie_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mext_review\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ext_review\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review, ext_review \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labelled_movie_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m], labelled_movie_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mext_review\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mExtractiveTextSummarizer.run_article_summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticle)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#algorithm for scoring a sentence by its words\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m sentence_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_sentence_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# getting the threshold\u001b[39;00m\n\u001b[1;32m     76\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_threshold_score(sentence_scores)\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mExtractiveTextSummarizer._calculate_sentence_scores\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m word_weight \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     48\u001b[0m             sentence_wordcount_without_stop_words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 50\u001b[0m     sentence_weights[sentence[:\u001b[38;5;241m7\u001b[39m]] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sentence_wordcount_without_stop_words\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sentence_weights\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#\n",
    "the error here is to show when alpha = 1.5, the threshold is too high to generate summaries\n",
    "ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "for review in labelled_movie_reviews['Summary']:\n",
    "    extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=1.5)\n",
    "    ext_review.append(extractive_summarizer.run_article_summary())\n",
    "labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "for review, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "    score = extractive_summarizer.get_rouge_score(hypothesis_text=review, reference_text=ext_review)\n",
    "    ext_recall.append(score[0]['rouge-1']['r'])\n",
    "    ext_precision.append(score[0]['rouge-1']['p'])\n",
    "    ext_f1.append(score[0]['rouge-1']['f'])\n",
    "    \n",
    "labelled_movie_reviews['ext_recall'] = ext_recall_1\n",
    "labelled_movie_reviews['ext_precision'] = ext_precision_1\n",
    "labelled_movie_reviews['ext_f1'] = ext_f1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76808efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.00</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rouge-1 f1 score</th>\n",
       "      <td>0.486166</td>\n",
       "      <td>0.524447</td>\n",
       "      <td>0.561191</td>\n",
       "      <td>0.620801</td>\n",
       "      <td>0.658563</td>\n",
       "      <td>0.700978</td>\n",
       "      <td>0.728648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1.00      0.95      0.90      0.85      0.80      0.75  \\\n",
       "Rouge-1 f1 score  0.486166  0.524447  0.561191  0.620801  0.658563  0.700978   \n",
       "\n",
       "                      0.70  \n",
       "Rouge-1 f1 score  0.728648  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_tune_results = pd.DataFrame(index=['Rouge-1 f1 score'])\n",
    "#ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "for al in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]:\n",
    "    ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "    for review in labelled_movie_reviews['Summary']:\n",
    "        extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=al)\n",
    "        ext_review.append(extractive_summarizer.run_article_summary())\n",
    "    labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "    for review, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "        score = extractive_summarizer.get_rouge_score(hypothesis_text=review, reference_text=ext_review)\n",
    "        ext_recall.append(score[0]['rouge-1']['r'])\n",
    "        ext_precision.append(score[0]['rouge-1']['p'])\n",
    "        ext_f1.append(score[0]['rouge-1']['f'])\n",
    "\n",
    "    #labelled_movie_reviews['ext_recall'] = ext_recall_1\n",
    "    #labelled_movie_reviews['ext_precision'] = ext_precision_1\n",
    "    labelled_movie_reviews['ext_f1'] = ext_f1\n",
    "    alpha_tune_results[al] = np.mean(labelled_movie_reviews['ext_f1'])\n",
    "    #print('alpha=', 1.0)\n",
    "    #print(np.mean(labelled_movie_reviews['ext_f1']))\n",
    "    #print(np.mean(labelled_movie_reviews['ext_precision']))\n",
    "    #print(np.mean(labelled_movie_reviews['ext_recall']))\n",
    "alpha_tune_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee93269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_review, ext_recall, ext_precision, ext_f1 = [], [], [], []\n",
    "for review in labelled_movie_reviews['Summary']:\n",
    "    extractive_summarizer = ExtractiveTextSummarizer(article=review, alpha=0.7)\n",
    "    ext_review.append(extractive_summarizer.run_article_summary())\n",
    "labelled_movie_reviews['ext_review'] = ext_review\n",
    "\n",
    "for review, ext_review in zip(labelled_movie_reviews['Summary'], labelled_movie_reviews['ext_review']):\n",
    "    score = extractive_summarizer.get_rouge_score(hypothesis_text=review, reference_text=ext_review)\n",
    "    ext_recall.append(score[0]['rouge-1']['r'])\n",
    "    ext_precision.append(score[0]['rouge-1']['p'])\n",
    "    ext_f1.append(score[0]['rouge-1']['f'])\n",
    "\n",
    "labelled_movie_reviews['ext_recall'] = ext_recall\n",
    "labelled_movie_reviews['ext_precision'] = ext_precision\n",
    "labelled_movie_reviews['ext_f1'] = ext_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcf0b2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>ext_review</th>\n",
       "      <th>ext_f1</th>\n",
       "      <th>ext_recall</th>\n",
       "      <th>ext_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production. Michael Sheen n...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Woody Allen is still fully in control of the s...</td>\n",
       "      <td>Woody Allen is still fully in control of the s...</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>This movie is slower than a soap opera. As a d...</td>\n",
       "      <td>This movie is slower than a soap opera. As a d...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>This is a movie that seems to be telling us wh...</td>\n",
       "      <td>This is a movie that seems to be telling us wh...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  The first episode I saw struck me as so nasty ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  Woody Allen is still fully in control of the s...   \n",
       "3  This movie is slower than a soap opera. As a d...   \n",
       "4  This is a movie that seems to be telling us wh...   \n",
       "\n",
       "                                          ext_review    ext_f1  ext_recall  \\\n",
       "0  The first episode I saw struck me as so nasty ...  1.000000         1.0   \n",
       "1  A wonderful little production. Michael Sheen n...  0.666667         1.0   \n",
       "2  Woody Allen is still fully in control of the s...  0.776119         1.0   \n",
       "3  This movie is slower than a soap opera. As a d...  1.000000         1.0   \n",
       "4  This is a movie that seems to be telling us wh...  1.000000         1.0   \n",
       "\n",
       "   ext_precision  \n",
       "0       1.000000  \n",
       "1       0.500000  \n",
       "2       0.634146  \n",
       "3       1.000000  \n",
       "4       1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_movie_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76a35c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>0.999418</td>\n",
       "      <td>0.647747</td>\n",
       "      <td>0.728648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIAN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Recall  Precision        F1\n",
       "MEAN    0.999418   0.647747  0.728648\n",
       "MAX     1.000000   1.000000  1.000000\n",
       "MIN     0.941176   0.023256  0.045455\n",
       "MEDIAN  1.000000   0.641026  0.781250"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.DataFrame(index=['MEAN', 'MAX', 'MIN', 'MEDIAN'], columns=['Recall', 'Precision', 'F1'])\n",
    "#f1_list, recall_list, precision_list = [],[],[]\n",
    "f1_list = [np.mean(labelled_movie_reviews['ext_f1']), max(labelled_movie_reviews['ext_f1']), \\\n",
    "               min(labelled_movie_reviews['ext_f1']), np.median(labelled_movie_reviews['ext_f1'])]\n",
    "\n",
    "recall_list = [np.mean(labelled_movie_reviews['ext_recall']), max(labelled_movie_reviews['ext_recall']), \\\n",
    "               min(labelled_movie_reviews['ext_recall']), np.median(labelled_movie_reviews['ext_recall'])]\n",
    "\n",
    "precision_list = [np.mean(labelled_movie_reviews['ext_precision']), max(labelled_movie_reviews['ext_precision']), \\\n",
    "               min(labelled_movie_reviews['ext_precision']), np.median(labelled_movie_reviews['ext_precision'])]\n",
    "\n",
    "stat['Recall'] = recall_list\n",
    "stat['Precision'] = precision_list\n",
    "stat['F1'] = f1_list\n",
    "stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da4e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f64f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>abs_summary</th>\n",
       "      <th>abs_recall</th>\n",
       "      <th>abs_precision</th>\n",
       "      <th>abs_f1</th>\n",
       "      <th>ext_summary</th>\n",
       "      <th>ext_recall</th>\n",
       "      <th>ext_precision</th>\n",
       "      <th>ext_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Oz is known for its brutality and unflinching ...</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "      <td>\"The actors are extremely well chosen- Michael...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>A wonderful little production. A masterful pro...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Woody Allen is still fully in control of the s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>This was the most I'd laughed at one of Woody'...</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>This movie is slower than a soap opera. As a d...</td>\n",
       "      <td>negative</td>\n",
       "      <td>A little boy (Jake) thinks there's a zombie in...</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>As a drama the movie is watchable. Parents are...</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>This is a movie that seems to be telling us wh...</td>\n",
       "      <td>positive</td>\n",
       "      <td>\"Love in the Time of Money\" is a visually stun...</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.202020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                             Summary sentiment  \\\n",
       "0  The first episode I saw struck me as so nasty ...  positive   \n",
       "1  A wonderful little production. The filming tec...  positive   \n",
       "2  Woody Allen is still fully in control of the s...  positive   \n",
       "3  This movie is slower than a soap opera. As a d...  negative   \n",
       "4  This is a movie that seems to be telling us wh...  positive   \n",
       "\n",
       "                                         abs_summary  abs_recall  \\\n",
       "0  Oz is known for its brutality and unflinching ...    0.422222   \n",
       "1  \"The actors are extremely well chosen- Michael...    0.400000   \n",
       "2  This was the most I'd laughed at one of Woody'...    0.170732   \n",
       "3  A little boy (Jake) thinks there's a zombie in...    0.361702   \n",
       "4  \"Love in the Time of Money\" is a visually stun...    0.109091   \n",
       "\n",
       "   abs_precision    abs_f1                                        ext_summary  \\\n",
       "0       0.542857  0.475000  One of the other reviewers has mentioned that ...   \n",
       "1       0.727273  0.516129  A wonderful little production. A masterful pro...   \n",
       "2       0.241379  0.200000  I thought this was a wonderful way to spend ti...   \n",
       "3       0.531250  0.430380  As a drama the movie is watchable. Parents are...   \n",
       "4       0.272727  0.155844  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "   ext_recall  ext_precision    ext_f1  \n",
       "0    0.222222       0.256410  0.238095  \n",
       "1    0.175000       0.466667  0.254545  \n",
       "2    0.365854       0.365854  0.365854  \n",
       "3    0.617021       0.828571  0.707317  \n",
       "4    0.181818       0.227273  0.202020  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abs stats\n",
    "labelled_movie_reviews = pd.read_csv(\"../data/review_evaluation.csv\", index_col=0)\n",
    "labelled_movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "441058a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEAN</th>\n",
       "      <td>0.395646</td>\n",
       "      <td>0.486998</td>\n",
       "      <td>0.428649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIAN</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.438356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Recall  Precision        F1\n",
       "MEAN    0.395646   0.486998  0.428649\n",
       "MAX     0.960000   1.000000  0.891892\n",
       "MIN     0.081081   0.103448  0.090909\n",
       "MEDIAN  0.384615   0.516129  0.438356"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.DataFrame(index=['MEAN', 'MAX', 'MIN', 'MEDIAN'], columns=['Recall', 'Precision', 'F1'])\n",
    "f1_list, recall_list, precision_list = [],[],[]\n",
    "f1_list = [np.mean(labelled_movie_reviews['abs_f1']), max(labelled_movie_reviews['abs_f1']), \\\n",
    "               min(labelled_movie_reviews['abs_f1']), np.median(labelled_movie_reviews['abs_f1'])]\n",
    "\n",
    "recall_list = [np.mean(labelled_movie_reviews['abs_recall']), max(labelled_movie_reviews['abs_recall']), \\\n",
    "               min(labelled_movie_reviews['abs_recall']), np.median(labelled_movie_reviews['abs_recall'])]\n",
    "\n",
    "precision_list = [np.mean(labelled_movie_reviews['abs_precision']), max(labelled_movie_reviews['abs_precision']), \\\n",
    "               min(labelled_movie_reviews['abs_precision']), np.median(labelled_movie_reviews['abs_precision'])]\n",
    "\n",
    "stat['Recall'] = recall_list\n",
    "stat['Precision'] = precision_list\n",
    "stat['F1'] = f1_list\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed142f6",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "\n",
    "### 8. Programmatic evaluation\n",
    "\n",
    "- We wrap up all the previous steps into an `ExtractiveTextSummarizer` class \n",
    "- To evaluate the effectiveness of the summarisation at different thresholds, we have manually summarised 101 movie reviews \n",
    "- Our human-labelled summary serves as a reference to estimate the algorithm's ability to pick out important aspects of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7226c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_movie_reviews = pd.read_csv(DATA_PATH / \"review_evaluation.csv\", index_col=0).iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a77c3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractiveTextSummarizer:\n",
    "    def __init__(self, article: str, alpha: float = 1.0) -> None:\n",
    "        self.article = article\n",
    "        self.alpha = alpha         \n",
    "        self.frequency_table = defaultdict(int)\n",
    "\n",
    "    def _create_dictionary_table(self, stemmer: Any = None) -> dict:\n",
    "   \n",
    "        #removing stop words\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        word_vector = word_tokenize(self.article)\n",
    "\n",
    "        # instantiate the stemmer \n",
    "        if stemmer is None: \n",
    "            stemmer = PorterStemmer()\n",
    "\n",
    "        stemmed_word_vector = [stemmer.stem(word) for word in word_vector]\n",
    "        for word in stemmed_word_vector:\n",
    "            if word not in stop_words:\n",
    "                self.frequency_table[word] += 1\n",
    "\n",
    "        return self.frequency_table\n",
    "\n",
    "\n",
    "    def _calculate_sentence_scores(self, sentences: npt.ArrayLike) -> dict:   \n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_weights = defaultdict(int)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_wordcount_without_stop_words = 0\n",
    "\n",
    "            for word_weight in self.frequency_table:\n",
    "                sentence_weights[sentence[:7]] += self.frequency_table[word_weight]\n",
    "\n",
    "                if word_weight in sentence.lower():\n",
    "                    sentence_wordcount_without_stop_words += 1\n",
    "\n",
    "            sentence_weights[sentence[:7]] /= sentence_wordcount_without_stop_words\n",
    "\n",
    "        return sentence_weights\n",
    "\n",
    "\n",
    "    def _calculate_threshold_score(self, sentence_weight: dict) -> float:\n",
    "        return np.mean(list(sentence_weight.values())) * self.alpha\n",
    "\n",
    "\n",
    "    def _get_article_summary(self, sentences: npt.ArrayLike, sentence_weights: dict, threshold: float) -> str:\n",
    "        article_summary = [sentence for sentence in sentences if sentence[:7] in sentence_weights and sentence_weights.get(sentence[:7]) >= threshold]\n",
    "\n",
    "        return \" \".join(article_summary)\n",
    "\n",
    "    def run_article_summary(self):\n",
    "\n",
    "        #creating a dictionary for the word frequency table\n",
    "        _ = self._create_dictionary_table()\n",
    "\n",
    "        #tokenizing the sentences\n",
    "        sentences = sent_tokenize(self.article)\n",
    "\n",
    "        #algorithm for scoring a sentence by its words\n",
    "        sentence_scores = self._calculate_sentence_scores(sentences)\n",
    "\n",
    "        # getting the threshold\n",
    "        threshold = self._calculate_threshold_score(sentence_scores)\n",
    "\n",
    "        #producing the summary\n",
    "        article_summary = self._get_article_summary(sentences, sentence_scores, threshold)\n",
    "\n",
    "        return article_summary\n",
    "\n",
    "    def get_rouge_score(self, hypothesis_text: str, reference_text: str) -> npt.ArrayLike:\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hypothesis_text, reference_text)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a324b",
   "metadata": {},
   "source": [
    "- We store the results the ROUGE-1 F1 of each summarisation under their respective alpha thresholds and calculate the mean values of 10 randomly chosen articles\n",
    "- Given that we consider 20% of the original length to be an acceptable amount, we select 0.95 as the final threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d0ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for reproducibility\n",
    "random.seed(2022)\n",
    "random_subset = random.sample(range(101), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef4b1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = defaultdict(list)\n",
    "percentage_summarised = defaultdict(list)\n",
    "\n",
    "for idx, article in enumerate(labelled_movie_reviews.loc[random_subset, \"review\"].values):\n",
    "    ext = ExtractiveTextSummarizer(article=article)\n",
    "    original_article_length = len(article.split())\n",
    "    for alpha in alpha_values: \n",
    "        ext.alpha = alpha\n",
    "        article_summary = ext.run_article_summary() \n",
    "        rouge_score = ext.get_rouge_score(\n",
    "            hypothesis_text=article_summary, \n",
    "            reference_text=labelled_movie_reviews.loc[idx, \"Summary\"])\n",
    "\n",
    "        _, _, f1 = rouge_score[0].get(\"rouge-1\").values()\n",
    "\n",
    "        percentage_summarised[alpha].append(len(article_summary.split()) / original_article_length)\n",
    "        result[alpha].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f3976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha value of 0.95\n",
      "Score: 0.123\n",
      "Percentage summarised: 22.75%\n",
      "Alpha value of 1.05\n",
      "Score: 0.119\n",
      "Percentage summarised: 21.79%\n",
      "Alpha value of 1.15\n",
      "Score: 0.110\n",
      "Percentage summarised: 16.39%\n",
      "Alpha value of 1.25\n",
      "Score: 0.083\n",
      "Percentage summarised: 11.54%\n"
     ]
    }
   ],
   "source": [
    "final_scores = zip(\n",
    "    alpha_values, \n",
    "    map(np.mean, result.values()),\n",
    "    map(np.mean, percentage_summarised.values())\n",
    "    )\n",
    "\n",
    "for alpha, score, percentage in final_scores: \n",
    "    print(f\"Alpha value of {alpha:.02f}\")\n",
    "    print(f\"Score: {score:.03f}\")\n",
    "    print(f\"Percentage summarised: {percentage:.02%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df817c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelled_movie_reviews = pd.read_csv(\"../data/review_evaluation.csv\", index_col=0).iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea718ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>The first episode I saw struck me as so nasty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Woody Allen is still fully in control of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>This movie is slower than a soap opera. As a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>This is a movie that seems to be telling us wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My guess would be this was originally going to...</td>\n",
       "      <td>Confused, abbreviated storyline. I was never c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
       "      <td>\"The Chilling\" is not funny and is not even \"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
       "      <td>This is the worst movie I have ever seen, as w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I have been a Mario fan for as long as I can r...</td>\n",
       "      <td>Super Mario Galaxy is the latest installment i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>This short film that inspired the soon-to-be f...</td>\n",
       "      <td>Spatula Madness is the short film that inspire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  \\\n",
       "0    One of the other reviewers has mentioned that ...   \n",
       "1    A wonderful little production. The filming tec...   \n",
       "2    I thought this was a wonderful way to spend ti...   \n",
       "3    Basically there's a family where a little boy ...   \n",
       "4    Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "..                                                 ...   \n",
       "96   My guess would be this was originally going to...   \n",
       "97   Well, I like to watch bad horror B-Movies, cau...   \n",
       "98   This IS the worst movie I have ever seen, as w...   \n",
       "99   I have been a Mario fan for as long as I can r...   \n",
       "100  This short film that inspired the soon-to-be f...   \n",
       "\n",
       "                                               Summary  \n",
       "0    The first episode I saw struck me as so nasty ...  \n",
       "1    A wonderful little production. The filming tec...  \n",
       "2    Woody Allen is still fully in control of the s...  \n",
       "3    This movie is slower than a soap opera. As a d...  \n",
       "4    This is a movie that seems to be telling us wh...  \n",
       "..                                                 ...  \n",
       "96   Confused, abbreviated storyline. I was never c...  \n",
       "97   \"The Chilling\" is not funny and is not even \"i...  \n",
       "98   This is the worst movie I have ever seen, as w...  \n",
       "99   Super Mario Galaxy is the latest installment i...  \n",
       "100  Spatula Madness is the short film that inspire...  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_movie_reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "37e987721a07d9a801a65e99628dc1f05d14dfb697773d267e80d3ef33c8e70f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
